{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python Dependencies\n",
    "Run the following code cell to install the required python packages.\n",
    "Note: your python environment should be python 3.8 or newer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.7.5 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.7.5)\n",
      "Requirement already satisfied: metric_learn==0.7.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: nltk==3.9.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: numpy==1.24.4 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.24.4)\n",
      "Requirement already satisfied: pandas==2.0.3 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: scikit_learn==1.2.2 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: opencv-python in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.10.0.84)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from matplotlib==3.7.5->-r requirements.txt (line 1)) (6.4.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from metric_learn==0.7.0->-r requirements.txt (line 2)) (1.10.1)\n",
      "Requirement already satisfied: click in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from scikit_learn==1.2.2->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.5->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /users/3/olso9295/.conda/envs/myenv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.7.5->-r requirements.txt (line 1)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, download the annotated data from the ICDAR 2024 MapText competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/records/11516933/files/rumsey_train.json\n",
    "!wget https://zenodo.org/records/11516933/files/rumsey_val.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Map Images\n",
    "Optionally, you can download the source map images for these annotations. These images take up roughly 2 GB of disk storage, and you can download them by running the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/records/11516933/files/train.zip\n",
    "!unzip train.zip\n",
    "!wget https://zenodo.org/records/11516933/files/val.zip\n",
    "!unzip val.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to delete the .zip files for the previous download\n",
    "!rm -rf train.zip\n",
    "!rm -rf val.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct and Evaluate Linkage Graphs\n",
    "First, fill in the variables in the cell below to select which linkage graph method you want to use. Then, run the cell to construct linkage graphs using that method, and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing dict\n",
      "loading annotations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m linkage_method \u001b[38;5;241m=\u001b[39m LinkageMethod(prims_mst, FeatureNode\u001b[38;5;241m.\u001b[39mEdgeCostFunction([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Uncomment the following lines to create MSTs using the Mahalanobis distance\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# note: training the Mahalanobis metric will take several minutes.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mahalanobis_metric_for_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmap_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_sample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m linkage_method \u001b[38;5;241m=\u001b[39m LinkageMethod(prims_mst, MahalanobisMetric(M))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# set the linkage_method as follows to create character distance threshold linkage graphs\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#linkage_method = LinkageMethod(distance_threshold_graph, FeatureNode.Distance)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# name the output file for your method by setting the \"name\" variable.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# this output file will be stored in a file called \"results\"\u001b[39;00m\n",
      "File \u001b[0;32m~/multiword-linkage-graph/scripts/cross_validation_mahalanobis.py:24\u001b[0m, in \u001b[0;36mtrain_mahalanobis_metric_for_fold\u001b[0;34m(fold_train_set, fold_name, annotations_filepath)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_mahalanobis_metric_for_fold\u001b[39m(fold_train_set, fold_name, annotations_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_annotations.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mload_all_maps_into_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotations_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_train_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_validation_mahalanobis_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fold_name, exist_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_validation_mahalanobis_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fold_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pairs_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/multiword-linkage-graph/scripts/collect_map_data.py:37\u001b[0m, in \u001b[0;36mload_all_maps_into_df\u001b[0;34m(map_annotations_filepath, filtered_ids_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m num_cores \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mnum_cores) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 37\u001b[0m     df_list \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_df_from_map_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_graphs_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(df_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "sys.path.append(os.getcwd() + \"/scripts\")\n",
    "from map_graph import FeatureNode, prims_mst, distance_threshold_graph, MahalanobisMetric\n",
    "from compare_linkages import map_list_compare_linkages, get_stats_from_results_file, LinkageMethod\n",
    "from cross_validation_mahalanobis import train_mahalanobis_metric_for_fold\n",
    "map_ids = []\n",
    "# change MAP_SAMPLE_SIZE to change the number of maps you randomly select.\n",
    "MAP_SAMPLE_SIZE = 10\n",
    "# to use the validation maps instead, change \"annotations_filepath\" from\n",
    "# \"rumsey_train.json\" to \"rumsey_val.json\"\n",
    "annotations_filepath = \"rumsey_train.json\"\n",
    "with open(annotations_filepath, \"r\") as f:\n",
    "    for map_annotation in json.load(f):\n",
    "        map_ids.append(map_annotation[\"image\"])\n",
    "    map_sample = random.sample(map_ids, MAP_SAMPLE_SIZE)\n",
    "    # you can change the linkage method here by changing the \"linkage_method\" variable\n",
    "    # use the following variable for the linkage method presented in our paper\n",
    "    linkage_method = LinkageMethod(prims_mst, FeatureNode.EdgeCostFunction([1, 1, 1]))\n",
    "    # Uncomment the following lines to create MSTs using the Mahalanobis distance\n",
    "    # note: training the Mahalanobis metric will take several minutes.\n",
    "    \"\"\" M = train_mahalanobis_metric_for_fold([map_id for map_id in map_ids if map_id not in map_sample], \"random_sample\", annotations_filepath)\n",
    "    linkage_method = LinkageMethod(prims_mst, MahalanobisMetric(M)) \"\"\"\n",
    "    # set the linkage_method as follows to create character distance threshold linkage graphs\n",
    "    #linkage_method = LinkageMethod(distance_threshold_graph, FeatureNode.Distance)\n",
    "\n",
    "    # name the output file for your method by setting the \"name\" variable.\n",
    "    # this output file will be stored in a file called \"results\"\n",
    "    name = \"train_edge_cost_heuristic_metric\"\n",
    "    output_file_name = \"results/\" + name + \".json\"\n",
    "    # Create the \"results\" folder if it doesn't exist\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    map_list_compare_linkages(map_sample, name, annotations_filepath, linkage_method, output_file_name)\n",
    "    get_stats_from_results_file(output_file_name, annotations_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Linkage Graphs\n",
    "To visualize the linkage graphs drawn on various maps, you can run the following code cell.\n",
    "Note: you will need to have downloaded the map images in order to create these visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing dict\n",
      "loading annotations\n",
      "47\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "sys.path.append(os.getcwd() + \"/scripts\")\n",
    "import draw_features_and_linkages as dfl\n",
    "import map_graph\n",
    "import multiword_name_extraction\n",
    "\n",
    "# change this variable to choose which map file you want to visualize\n",
    "map_filename = \"rumsey/train/8179000_h6_w11.png\"\n",
    "mg = map_graph.MapGraph(map_filename)\n",
    "map_graph.prims_mst(mg.nodes, map_graph.FeatureNode.EdgeCostFunction([1, 1, 1]))\n",
    "map_annotations = multiword_name_extraction.extract_map_data_from_all_annotations(map_filename)\n",
    "dfl.draw_features_and_linkages(map_filename, mg, \"equation_1.png\", map_dir=os.getcwd(), show_image=True)\n",
    "mg = map_graph.MapGraph(map_filename)\n",
    "map_graph.distance_threshold_graph(mg.nodes)\n",
    "map_annotations = multiword_name_extraction.extract_map_data_from_all_annotations(map_filename)\n",
    "dfl.draw_features_and_linkages(map_filename, mg, \"character_distance_threshold.png\",map_dir=os.getcwd(), show_image=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
